{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sources:**\n",
    "\n",
    "The code used for TTA and inference calculations:\n",
    "\n",
    "[1] https://github.com/taheeraahmed/master-thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import zipfile\n",
    "import time\n",
    "from statistics import mean, stdev\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "# Data Manipulation Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Progress Bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Machine Learning Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import timm for models\n",
    "import timm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "ZIP_PATH = '/cluster/home/bjorneme/projects/Data/chestX-ray14.zip'\n",
    "EXTRACTED_PATH = '/cluster/home/bjorneme/projects/Data/chestX-ray14-extracted'\n",
    "BACKBONE_PATH = '../../ChestX-ray14 Single Models/ConvNeXt_v2/convnext_v2_tta_backbone.pt'\n",
    "\n",
    "# Model\n",
    "MODEL_NAME = \"convnextv2_large.fcmae_ft_in22k_in1k\"\n",
    "\n",
    "# Disease Labels\n",
    "disease_labels = [\n",
    "    'Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', 'Edema',\n",
    "    'Emphysema', 'Fibrosis', 'Effusion', 'Pneumonia', 'Pleural_Thickening',\n",
    "    'Cardiomegaly', 'Nodule', 'Mass', 'Hernia'\n",
    "]\n",
    "\n",
    "# Other parameters\n",
    "SEED = 42\n",
    "NUM_WORKERS = 32\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Device Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set Seed for Reproducibility**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=SEED):\n",
    "    \"\"\"\n",
    "    Sets the seed to ensure reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Apply the seed\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print Hardware Info**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.4.0+cu121\n",
      "CUDA 12.1\n",
      "GPU: NVIDIA H100 80GB HBM3, 81559 MiB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpu_info = subprocess.check_output([\n",
    "    \"nvidia-smi\",\n",
    "    \"--query-gpu=name,memory.total\",\"--format=csv,noheader\"]\n",
    ").decode()\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"CUDA\", torch.version.cuda)\n",
    "print(f\"GPU: {gpu_info}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 1: Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(zip_path, extracted_path):\n",
    "    \"\"\"\n",
    "    Extracts the ZIP file of the dataset.\n",
    "    \"\"\"\n",
    "    os.makedirs(extracted_path, exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "# Extract ChestX-ray14 dataset\n",
    "# TODO: Uncomment to extract data from zip\n",
    "# extract_data(ZIP_PATH, EXTRACTED_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 2: Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(csv_path, extracted_path):\n",
    "    \"\"\"\n",
    "    Read labels from CSV, maps images to paths, and create binary disease labels.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the CSV containing labels\n",
    "    labels_df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Create binary columns for each disease label\n",
    "    for disease in disease_labels:\n",
    "        labels_df[disease] = labels_df['Finding Labels'].str.contains(disease).astype(int)\n",
    "\n",
    "    # Create binary column for 'No Finding'\n",
    "    labels_df['No Finding'] = labels_df['Finding Labels'].str.contains('No Finding').astype(int)\n",
    "\n",
    "    # Map images to their full path\n",
    "    labels_df['Path'] = labels_df['Image Index'].map(\n",
    "        {os.path.basename(path): path for path in glob(os.path.join(extracted_path, '**', 'images', '*.png'))}\n",
    "    )\n",
    "    \n",
    "    return labels_df\n",
    "\n",
    "# Path to the labels CSV file\n",
    "labels_csv_path = os.path.join(EXTRACTED_PATH, 'Data_Entry_2017.csv')\n",
    "\n",
    "# Load and preprocess the labels\n",
    "df = load_labels(labels_csv_path, EXTRACTED_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 78614. Number of unique patients: 21563\n",
      "Validation size: 11212. Number of unique patients: 3081\n",
      "Test size: 22294. Number of unique patients: 6161\n"
     ]
    }
   ],
   "source": [
    "# Split based on patients\n",
    "unique_patients = df['Patient ID'].unique()\n",
    "\n",
    "# Split patients into training, validation and test sets\n",
    "train_val_patients, test_patients = train_test_split(\n",
    "    unique_patients, test_size=0.2, random_state=SEED\n",
    ")\n",
    "train_patients, val_patients = train_test_split(\n",
    "    train_val_patients, test_size=0.125, random_state=SEED\n",
    ")\n",
    "\n",
    "# Create dataframes for training, validation, and test sets\n",
    "train_df = df[df['Patient ID'].isin(train_patients)].reset_index(drop=True)\n",
    "val_df = df[df['Patient ID'].isin(val_patients)].reset_index(drop=True)\n",
    "test_df = df[df['Patient ID'].isin(test_patients)].reset_index(drop=True)\n",
    "\n",
    "# Verify Split Sizes\n",
    "print(f\"Train dataset size: {len(train_df)}. Number of unique patients: {len(train_patients)}\")\n",
    "print(f\"Validation size: {len(val_df)}. Number of unique patients: {len(val_patients)}\")\n",
    "print(f\"Test size: {len(test_df)}. Number of unique patients: {len(test_patients)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Dataset for Chest X-ray images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXrayDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Create dataset for Chest X-ray images.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Get image and labels\n",
    "        img_path = self.df.iloc[idx]['Path']\n",
    "        image = plt.imread(img_path)\n",
    "        label = self.df.iloc[idx][disease_labels].values.astype(np.float32)\n",
    "        \n",
    "        # Apply transformation on image\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Transformations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_transform=[0.485, 0.456, 0.406]\n",
    "std_transform=[0.229, 0.224, 0.225]\n",
    "\n",
    "# Define transformations for test data\n",
    "test_transforms = transforms.Compose([\n",
    "\n",
    "    # Convert image to PIL format\n",
    "    transforms.ToPILImage(),\n",
    "\n",
    "    # Convert to 3 channels\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "\n",
    "    # Resize the image to 256x256\n",
    "    transforms.Resize((256,256)),\n",
    "\n",
    "    # Create 10 crops\n",
    "    transforms.TenCrop(224),\n",
    "    transforms.Lambda(lambda crops: torch.stack([\n",
    "        transforms.ToTensor()(crop) for crop in crops\n",
    "    ])),\n",
    "\n",
    "    # Normalize using ImageNet mean and std\n",
    "    transforms.Lambda(lambda crops: torch.stack(\n",
    "        [transforms.Normalize(mean_transform, std_transform)(crop) for crop in crops]\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Test Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ChestXrayDataset(test_df, transform=test_transforms)\n",
    "reduced_dataset = Subset(test_dataset, list(range(BATCH_SIZE*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Test DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(reduced_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 3: Build the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model\n",
    "class MultiLabelClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Label Classification Model using ConvNeXt v2 as the base model.\n",
    "    \"\"\"\n",
    "    def __init__(self, device, model_name, num_classes=len(disease_labels)):\n",
    "        super(MultiLabelClassifier, self).__init__()\n",
    "\n",
    "        # Load pre-trained ConvNeXt v2 model\n",
    "        self.base_model = timm.create_model(model_name, pretrained=True).to(device)\n",
    "\n",
    "        # Replace the classification head to match the number of disease labels\n",
    "        self.base_model.head.fc = nn.Linear(self.base_model.head.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "# Initialize the Model\n",
    "convnext_v2_model = MultiLabelClassifier(device, MODEL_NAME)\n",
    "convnext_v2_model = nn.DataParallel(convnext_v2_model).to(device)\n",
    "\n",
    "# Load the model\n",
    "convnext_v2_model.load_state_dict(torch.load(\n",
    "    BACKBONE_PATH,\n",
    "    weights_only=True\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 4: Calculate Metrics Inference**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warm-up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = torch.randn(1,3,224,224).to(device)\n",
    "for _ in range(100):\n",
    "    _ = convnext_v2_model(dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference GPU Runtime and Peak Memory Usage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on Test Set: 100%|██████████| 100/100 [01:10<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference runtime: 638.76 ± 1.53 ms\n",
      "Throughput: 50 img/s\n",
      "\n",
      "Peak GPU memory allocated: 13.13 GB\n",
      "Peak GPU memory reserved: 16.58 GB\n"
     ]
    }
   ],
   "source": [
    "# Current wall-clock time\n",
    "torch.cuda.reset_peak_memory_stats(device)\n",
    "\n",
    "# List to store batch time (ms)\n",
    "batch_times = []\n",
    "\n",
    "# Used for start and end time record of GPU\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end   = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "# Progress bar\n",
    "progress_bar = tqdm(test_loader, desc=\"Evaluating on Test Set\")\n",
    "\n",
    "# Set to evaluation mode\n",
    "convnext_v2_model.eval()\n",
    "\n",
    "# Disable gradients for evaluation\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in progress_bar:\n",
    "\n",
    "        # Retrieve input sizes\n",
    "        batch_size, ncrops, C, H, W = inputs.size()\n",
    "\n",
    "        # Move to device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Change to [batch_size * ncrops, C, H, W]\n",
    "        inputs = inputs.view(-1, C, H, W) \n",
    "\n",
    "        # Start GPU timer\n",
    "        start.record()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = convnext_v2_model(inputs)\n",
    "\n",
    "        # Stop GPU timer\n",
    "        end.record()\n",
    "\n",
    "        # Wait until the kernel is finished\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        # Save time in ms\n",
    "        batch_times.append(start.elapsed_time(end))\n",
    "\n",
    "mem_allocated  = torch.cuda.max_memory_allocated()\n",
    "mem_reserved = torch.cuda.max_memory_reserved()\n",
    "\n",
    "# Print Inference runtime\n",
    "print(f\"Inference runtime: {mean(batch_times):.2f} ± {stdev(batch_times):.2f} ms\")\n",
    "print(f\"Throughput: {((len(test_loader)/sum(batch_times))*1000)*BATCH_SIZE:.0f} img/s\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Print GPU Memory\n",
    "print(f\"Peak GPU memory allocated: {mem_allocated / 1000000000:.2f} GB\")\n",
    "print(f\"Peak GPU memory reserved: {mem_reserved / 1000000000:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB): 785.93\n"
     ]
    }
   ],
   "source": [
    "size = Path(BACKBONE_PATH).stat().st_size / (1000000)\n",
    "print(f\"Model size (MB): {size:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "master_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
