{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sources:**\n",
    "\n",
    "The code used for TTA and inference calculations:\n",
    "\n",
    "[1] https://github.com/taheeraahmed/master-thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mambavision in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: transformers in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (4.50.0)\n",
      "Requirement already satisfied: mamba_ssm in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (2.2.4)\n",
      "Requirement already satisfied: timm in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (1.0.15)\n",
      "Requirement already satisfied: einops==0.8.1 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from mambavision) (0.8.1)\n",
      "Requirement already satisfied: tensorboardX==2.6.2.2 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from mambavision) (2.6.2.2)\n",
      "Requirement already satisfied: requests==2.32.3 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from mambavision) (2.32.3)\n",
      "Requirement already satisfied: Pillow==11.1.0 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from mambavision) (11.1.0)\n",
      "Requirement already satisfied: filelock in /cluster/home/bjorneme/.local/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: torch in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from mamba_ssm) (2.4.0)\n",
      "Requirement already satisfied: ninja in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from mamba_ssm) (1.11.1.3)\n",
      "Requirement already satisfied: setuptools>=61.0.0 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from mamba_ssm) (75.1.0)\n",
      "Requirement already satisfied: torchvision in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from timm) (0.19.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from requests==2.32.3->mambavision) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from requests==2.32.3->mambavision) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from requests==2.32.3->mambavision) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from requests==2.32.3->mambavision) (2024.8.30)\n",
      "Requirement already satisfied: protobuf>=3.20 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from tensorboardX==2.6.2.2->mambavision) (5.28.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /cluster/home/bjorneme/.local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /cluster/home/bjorneme/.local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from torch->mamba_ssm) (1.14.0)\n",
      "Requirement already satisfied: networkx in /cluster/home/bjorneme/.local/lib/python3.11/site-packages (from torch->mamba_ssm) (3.3)\n",
      "Requirement already satisfied: jinja2 in /cluster/home/bjorneme/.local/lib/python3.11/site-packages (from torch->mamba_ssm) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from torch->mamba_ssm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from torch->mamba_ssm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from torch->mamba_ssm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from torch->mamba_ssm) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from torch->mamba_ssm) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from torch->mamba_ssm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from torch->mamba_ssm) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from torch->mamba_ssm) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from torch->mamba_ssm) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from torch->mamba_ssm) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from torch->mamba_ssm) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from torch->mamba_ssm) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mamba_ssm) (12.6.85)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /cluster/home/bjorneme/.local/lib/python3.11/site-packages (from jinja2->torch->mamba_ssm) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /cluster/home/bjorneme/.local/lib/python3.11/site-packages (from sympy->torch->mamba_ssm) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mambavision transformers mamba_ssm timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import zipfile\n",
    "import time\n",
    "from statistics import mean, stdev\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "# Data Manipulation Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Progress Bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Machine Learning Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Hugging Face transformers to load the MambaVision model\n",
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "ZIP_PATH = '/cluster/home/bjorneme/projects/Data/chestX-ray14.zip'\n",
    "EXTRACTED_PATH = '/cluster/home/bjorneme/projects/Data/chestX-ray14-extracted'\n",
    "BACKBONE_PATH = '../../ChestX-ray14 Single Models/MambaVision_Large/mambavision_L_tta_backbone.pt'\n",
    "\n",
    "# Model\n",
    "MODEL_NAME = \"nvidia/MambaVision-L-21K\"\n",
    "\n",
    "# Disease Labels\n",
    "disease_labels = [\n",
    "    'Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', 'Edema',\n",
    "    'Emphysema', 'Fibrosis', 'Effusion', 'Pneumonia', 'Pleural_Thickening',\n",
    "    'Cardiomegaly', 'Nodule', 'Mass', 'Hernia'\n",
    "]\n",
    "\n",
    "# Other parameters\n",
    "SEED = 42\n",
    "NUM_WORKERS = 32\n",
    "\n",
    "# Device Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set Seed for Reproducibility**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=SEED):\n",
    "    \"\"\"\n",
    "    Sets the seed to ensure reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Apply the seed\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print Hardware Info**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.4.0+cu121\n",
      "CUDA 12.1\n",
      "GPU: NVIDIA A100-SXM4-80GB, 81920 MiB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpu_info = subprocess.check_output([\n",
    "    \"nvidia-smi\",\n",
    "    \"--query-gpu=name,memory.total\",\"--format=csv,noheader\"]\n",
    ").decode()\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"CUDA\", torch.version.cuda)\n",
    "print(f\"GPU: {gpu_info}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 1: Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(zip_path, extracted_path):\n",
    "    \"\"\"\n",
    "    Extracts the ZIP file of the dataset.\n",
    "    \"\"\"\n",
    "    os.makedirs(extracted_path, exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "# Extract ChestX-ray14 dataset\n",
    "# TODO: Uncomment to extract data from zip\n",
    "# extract_data(ZIP_PATH, EXTRACTED_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 2: Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(csv_path, extracted_path):\n",
    "    \"\"\"\n",
    "    Read labels from CSV, maps images to paths, and create binary disease labels.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the CSV containing labels\n",
    "    labels_df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Create binary columns for each disease label\n",
    "    for disease in disease_labels:\n",
    "        labels_df[disease] = labels_df['Finding Labels'].str.contains(disease).astype(int)\n",
    "\n",
    "    # Create binary column for 'No Finding'\n",
    "    labels_df['No Finding'] = labels_df['Finding Labels'].str.contains('No Finding').astype(int)\n",
    "\n",
    "    # Map images to their full path\n",
    "    labels_df['Path'] = labels_df['Image Index'].map(\n",
    "        {os.path.basename(path): path for path in glob(os.path.join(extracted_path, '**', 'images', '*.png'))}\n",
    "    )\n",
    "    \n",
    "    return labels_df\n",
    "\n",
    "# Path to the labels CSV file\n",
    "labels_csv_path = os.path.join(EXTRACTED_PATH, 'Data_Entry_2017.csv')\n",
    "\n",
    "# Load and preprocess the labels\n",
    "df = load_labels(labels_csv_path, EXTRACTED_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 78614. Number of unique patients: 21563\n",
      "Validation size: 11212. Number of unique patients: 3081\n",
      "Test size: 22294. Number of unique patients: 6161\n"
     ]
    }
   ],
   "source": [
    "# Split based on patients\n",
    "unique_patients = df['Patient ID'].unique()\n",
    "\n",
    "# Split patients into training, validation and test sets\n",
    "train_val_patients, test_patients = train_test_split(\n",
    "    unique_patients, test_size=0.2, random_state=SEED\n",
    ")\n",
    "train_patients, val_patients = train_test_split(\n",
    "    train_val_patients, test_size=0.125, random_state=SEED\n",
    ")\n",
    "\n",
    "# Create dataframes for training, validation, and test sets\n",
    "train_df = df[df['Patient ID'].isin(train_patients)].reset_index(drop=True)\n",
    "val_df = df[df['Patient ID'].isin(val_patients)].reset_index(drop=True)\n",
    "test_df = df[df['Patient ID'].isin(test_patients)].reset_index(drop=True)\n",
    "\n",
    "# Verify Split Sizes\n",
    "print(f\"Train dataset size: {len(train_df)}. Number of unique patients: {len(train_patients)}\")\n",
    "print(f\"Validation size: {len(val_df)}. Number of unique patients: {len(val_patients)}\")\n",
    "print(f\"Test size: {len(test_df)}. Number of unique patients: {len(test_patients)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Dataset for Chest X-ray images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXrayDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Create dataset for Chest X-ray images.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Get image and labels\n",
    "        img_path = self.df.iloc[idx]['Path']\n",
    "        image = plt.imread(img_path)\n",
    "        label = self.df.iloc[idx][disease_labels].values.astype(np.float32)\n",
    "        \n",
    "        # Apply transformation on image\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Transformations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_transform=[0.485, 0.456, 0.406]\n",
    "std_transform=[0.229, 0.224, 0.225]\n",
    "\n",
    "# Define transformations for test data\n",
    "test_transforms = transforms.Compose([\n",
    "\n",
    "    # Convert image to PIL format\n",
    "    transforms.ToPILImage(),\n",
    "\n",
    "    # Convert to 3 channels\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "\n",
    "    # Resize the image to 256x256\n",
    "    transforms.Resize((256,256)),\n",
    "\n",
    "    # Create 10 crops\n",
    "    transforms.TenCrop(224),\n",
    "    transforms.Lambda(lambda crops: torch.stack([\n",
    "        transforms.ToTensor()(crop) for crop in crops\n",
    "    ])),\n",
    "\n",
    "    # Normalize using ImageNet mean and std\n",
    "    transforms.Lambda(lambda crops: torch.stack(\n",
    "        [transforms.Normalize(mean_transform, std_transform)(crop) for crop in crops]\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Test Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ChestXrayDataset(test_df, transform=test_transforms)\n",
    "reduced_dataset = Subset(test_dataset, list(range(1000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Test DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(reduced_dataset, batch_size=1, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 3: Build the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "/cluster/home/bjorneme/.conda/envs/master_thesis/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "2025-05-16 22:31:39.545155: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747427499.557012 3999355 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747427499.561149 3999355 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-16 22:31:39.581978: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model\n",
    "class MultiLabelClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Label Classification Model using MambaVision as the base model.\n",
    "    \"\"\"\n",
    "    def __init__(self, device, model_name=\"nvidia/MambaVision-T2-1K\", num_classes=len(disease_labels)):\n",
    "        super(MultiLabelClassifier, self).__init__()\n",
    "\n",
    "        # Load pre-trained MambaVision model\n",
    "        self.base_model = AutoModel.from_pretrained(model_name, trust_remote_code=True).to(device)\n",
    "\n",
    "        # Replace the classification head to match the number of disease labels\n",
    "        self.base_model.model.head = nn.Linear(self.base_model.model.head.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_pool, _ = self.base_model(x)\n",
    "        return self.base_model.model.head(avg_pool)\n",
    "\n",
    "# Initialize the Model\n",
    "mambavision_L_model = MultiLabelClassifier(device, MODEL_NAME)\n",
    "mambavision_L_model = nn.DataParallel(mambavision_L_model).to(device)\n",
    "\n",
    "# Load the model\n",
    "mambavision_L_model.load_state_dict(torch.load(\n",
    "    BACKBONE_PATH,\n",
    "    weights_only=True\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 4: Calculate Metrics Inference**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warm-up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = torch.randn(1,3,224,224).to(device)\n",
    "for _ in range(100):\n",
    "    _ = mambavision_L_model(dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference GPU Runtime and Peak Memory Usage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on Test Set: 100%|██████████| 1000/1000 [00:43<00:00, 22.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference runtime: 39.25 ± 1.40 ms\n",
      "Throughput: 25 img/s\n",
      "\n",
      "Peak GPU memory allocated: 1.20 GB\n",
      "Peak GPU memory reserved: 1.94 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Current wall-clock time\n",
    "torch.cuda.reset_peak_memory_stats(device)\n",
    "\n",
    "# List to store batch time (ms)\n",
    "batch_times = []\n",
    "\n",
    "# Used for start and end time record of GPU\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end   = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "# Progress bar\n",
    "progress_bar = tqdm(test_loader, desc=\"Evaluating on Test Set\")\n",
    "\n",
    "# Set to evaluation mode\n",
    "mambavision_L_model.eval()\n",
    "\n",
    "# Disable gradients for evaluation\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in progress_bar:\n",
    "\n",
    "        # Retrieve input sizes\n",
    "        batch_size, ncrops, C, H, W = inputs.size()\n",
    "\n",
    "        # Move to device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Change to [batch_size * ncrops, C, H, W]\n",
    "        inputs = inputs.view(-1, C, H, W) \n",
    "\n",
    "        # Start GPU timer\n",
    "        start.record()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = mambavision_L_model(inputs)\n",
    "\n",
    "        # Stop GPU timer\n",
    "        end.record()\n",
    "\n",
    "        # Wait until the kernel is finished\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        # Save time in ms\n",
    "        batch_times.append(start.elapsed_time(end))\n",
    "\n",
    "mem_allocated  = torch.cuda.max_memory_allocated()\n",
    "mem_reserved = torch.cuda.max_memory_reserved()\n",
    "\n",
    "# Print Inference runtime\n",
    "print(f\"Inference runtime: {mean(batch_times):.2f} ± {stdev(batch_times):.2f} ms\")\n",
    "print(f\"Throughput: {(len(test_loader)/sum(batch_times))*1000:.0f} img/s\")\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "# Print GPU Memory\n",
    "print(f\"Peak GPU memory allocated: {mem_allocated / 2**30:.2f} GB\")\n",
    "print(f\"Peak GPU memory reserved: {mem_reserved / 2**30:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB): 905.85\n"
     ]
    }
   ],
   "source": [
    "size = Path(BACKBONE_PATH).stat().st_size / (1000000)\n",
    "print(f\"Model size (MB): {size:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "master_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
