{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "import yaml\n",
    "\n",
    "# Data Manipulation Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path\n",
    "EXTRACTED_PATH = '/cluster/home/bjorneme/projects/Data/vinbigdata-chest-xray-abnormalities-detection-extracted'\n",
    "train_csv = os.path.join(EXTRACTED_PATH, 'train.csv')\n",
    "\n",
    "# Disease labels\n",
    "disease_labels = [\n",
    "    \"Aortic enlargement\", \"Atelectasis\", \"Calcification\", \"Cardiomegaly\",\n",
    "    \"Consolidation\", \"ILD\", \"Infiltration\", \"Lung Opacity\",\n",
    "    \"Nodule/Mass\", \"Other lesion\", \"Pleural effusion\", \"Pleural thickening\",\n",
    "    \"Pneumothorax\", \"Pulmonary fibrosis\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_dicom_image(path):\n",
    "    ds = pydicom.dcmread(path)\n",
    "    img = ds.pixel_array.astype(np.float32)\n",
    "    img = ((img - img.min()) / (img.max() - img.min()) * 255).astype(np.uint8)\n",
    "    return Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_annotation_to_yolo(group, img_size_override=None):\n",
    "    # Size image\n",
    "    img_path = group.iloc[0]['Path']\n",
    "    img_width, img_height = open_dicom_image(img_path).size\n",
    "    \n",
    "    lines = []\n",
    "    for _, row in group.iterrows():\n",
    "        x_min, y_min, x_max, y_max = row[['x_min','y_min','x_max','y_max']]\n",
    "        x_center = ((x_min + x_max) / 2) / img_width\n",
    "        y_center = ((y_min + y_max) / 2) / img_height\n",
    "        box_width = (x_max - x_min) / img_width\n",
    "        box_height = (y_max - y_min) / img_height\n",
    "        lines.append(f\"{int(row['class_id'])} {x_center:.6f} {y_center:.6f} {box_width:.6f} {box_height:.6f}\")\n",
    "    return img_path, lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(csv_path, image_path, disease_labels):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    for d in disease_labels:\n",
    "        df[d] = df['class_name'].str.contains(d).astype(int)\n",
    "    df['No finding'] = df['class_name'].str.contains('No finding').astype(int)\n",
    "    df['Path'] = df['image_id'].apply(lambda x: os.path.join(image_path, 'train', f\"{x}.dicom\"))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_split(df, split_name, base_dir):\n",
    "    for image_id, group in df.groupby('image_id'):\n",
    "        img_path, yolo_lines = convert_annotation_to_yolo(group)\n",
    "        img_filename = os.path.basename(img_path)\n",
    "        ext = os.path.splitext(img_filename)[1].lower()\n",
    "        img_dir = os.path.join(base_dir, \"images\", split_name)\n",
    "        label_dir = os.path.join(base_dir, \"labels\", split_name)\n",
    "        os.makedirs(img_dir, exist_ok=True)\n",
    "        os.makedirs(label_dir, exist_ok=True)\n",
    "        \n",
    "        pil_img = open_dicom_image(img_path)\n",
    "        img_filename = os.path.splitext(img_filename)[0] + \".png\"\n",
    "        pil_img.save(os.path.join(img_dir, img_filename))\n",
    "        \n",
    "        label_filename = os.path.splitext(img_filename)[0] + \".txt\"\n",
    "        with open(os.path.join(label_dir, label_filename), \"w\") as f:\n",
    "            f.write(\"\\n\".join(yolo_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 36096\n",
      "Train images: 3515, Val images: 879\n",
      "Processing training set...\n",
      "Processing validation set...\n"
     ]
    }
   ],
   "source": [
    "df = load_labels(train_csv, EXTRACTED_PATH, disease_labels)\n",
    "df = df[df['class_id'] != 14]\n",
    "print(f\"Train size: {df.shape[0]}\")\n",
    "\n",
    "unique_ids = df['image_id'].unique()\n",
    "train_ids, val_ids = train_test_split(unique_ids, test_size=0.2, random_state=42)\n",
    "train_df, val_df = df[df['image_id'].isin(train_ids)], df[df['image_id'].isin(val_ids)]\n",
    "print(f\"Train images: {len(train_ids)}, Val images: {len(val_ids)}\")\n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    os.makedirs(os.path.join(EXTRACTED_PATH, \"images\", split), exist_ok=True)\n",
    "    os.makedirs(os.path.join(EXTRACTED_PATH, \"labels\", split), exist_ok=True)\n",
    "\n",
    "print(\"Processing training set...\")\n",
    "# process_split(train_df, \"train\", EXTRACTED_PATH)\n",
    "print(\"Processing validation set...\")\n",
    "# process_split(val_df, \"val\", EXTRACTED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_yaml = {\n",
    "    \"train\": os.path.join(os.getcwd(), EXTRACTED_PATH, \"images\", \"train\"),\n",
    "    \"val\": os.path.join(os.getcwd(), EXTRACTED_PATH, \"images\", \"val\"),\n",
    "    \"nc\": 14,\n",
    "    \"names\": disease_labels\n",
    "}\n",
    "\n",
    "with open(\"data.yaml\", \"w\") as f:\n",
    "    yaml.dump(data_yaml, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8x-cls.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLO(\n",
       "  (model): ClassificationModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv(\n",
       "        (conv): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(400, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Conv(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (4): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-5): 6 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Conv(\n",
       "        (conv): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (6): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-5): 6 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Conv(\n",
       "        (conv): Conv2d(640, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (8): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(3200, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): Classify(\n",
       "        (conv): Conv(\n",
       "          (conv): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (drop): Dropout(p=0.0, inplace=True)\n",
       "        (linear): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "master_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
